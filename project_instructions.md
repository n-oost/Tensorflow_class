üîç Overview

The final project will assess your ability to apply multiple deep learning architectures using TensorFlow 2 and Keras. You must select a real dataset (image or time series), train at least two different deep learning models, and compare them in terms of:

    Architecture design

    Data preprocessing requirements

    Training process and challenges

    Speed and predictive performance

The emphasis is on demonstrating a deep understanding of architectures, preprocessing, and training concepts.
‚úÖ Project Requirements
Dataset Selection

    Choose a dataset from a reliable public source (e.g., Kaggle, UCI ML Repository, TensorFlow Datasets).

    Dataset must be not too small or oversimplified and appropriate for image or time-series modeling.

Model Application

    Data Preprocessing (Major Focus)

        Explain how you made the dataset ready for deep learning.

        For images: resizing, normalization, augmentation (rotation, flips, zoom, etc.).

        For time series: scaling, windowing, sequence padding, handling missing values.

        Justify why each preprocessing step was necessary for your chosen models.

    Model Architectures (Core Requirement)

        Train at least two different architectures from this course:

            CNNs (or Transfer Learning with CNNs)

            RNNs / LSTMs / GRUs

            Transformers (vision or sequence tasks)

            GANs (for generative tasks)

        Provide a clear justification of each model for the dataset.

        Describe the layers, structure, and differences between the chosen models.

    Training Process & Challenges

        Detail the training setup: optimizer, loss function, learning rate, batch size, dropout, epochs.

        Provide training and validation curves.

        Discuss challenges (e.g., overfitting, vanishing gradients, instability, GAN convergence issues).

        Explain how you addressed these issues.

    Comparison of Models

        Compare architectures on:

            Accuracy / predictive performance

            Training speed and efficiency

            Robustness and stability

        Use plots, tables, or side-by-side analysis to present comparisons.

Code Implementation

    Jupyter Notebook (.ipynb), well-structured with Markdown and explanations.

    All code executed with visible outputs.

    Organized for readability and reproducibility.

üì§ Submission Guidelines

    Report: PDF (6‚Äì10 pages, excluding title page).

    Code: Jupyter Notebook.

    Submit via FOL (submissions by email will not be accepted).

    Submission deadline: November 30, 11:59 PM

üìù Report Structure

    Title Page & Abstract

    Introduction (motivation, objectives, chosen dataset, relevance to deep learning)

    Methodology

        Dataset & preprocessing (with strong justification)

        Model architectures (at least 2)

        Training process & challenges

    Results & Comparison (performance + speed analysis)

    Conclusion & Future Work

    References

üé§ Presentation Requirement

    Duration: 8‚Äì10 minutes.

    Must include slides covering:

        Dataset & preprocessing

        Two chosen architectures

        Training process & challenges

        Results & comparison (performance + speed)

        Key conclusions

    Notebook Review: Quick walkthrough of notebook and outputs.

    Q&A: Be prepared to defend your architecture and training choices.

üìå Important Reminders

    You must implement and compare at least two architectures from this course.

    Focus on preprocessing, architectures, training process, and comparisons.

    Work must be original.